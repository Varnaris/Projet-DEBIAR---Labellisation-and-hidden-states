{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "KXQltZsTDd63",
   "metadata": {
    "id": "KXQltZsTDd63"
   },
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b916c7",
   "metadata": {
    "id": "b6b916c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8162cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\"\"\"\n",
    "!nvidia-smi\n",
    "\n",
    "#!pkill -u $USER -f python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112fb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"!kill 2086774 \n",
    "\n",
    "del tokenizer\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acXFHcPiRs9Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4832,
     "status": "ok",
     "timestamp": 1751915534514,
     "user": {
      "displayName": "Elouan",
      "userId": "04663354146870278787"
     },
     "user_tz": -120
    },
    "id": "acXFHcPiRs9Y",
    "outputId": "878177e0-39c1-4560-f9e1-dd77dcdefbe1"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "import bitsandbytes\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n",
    "\n",
    "model_name = \"unsloth/Mistral-Small-Instruct-2409-bnb-4bit\"\n",
    "#model_name = \"unsloth/Phi-4-mini-instruct-bnb-4bit\"\n",
    "#model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B-bnb-4bit\"\n",
    "#model_name = \"unsloth/Qwen2-7B-Instruct-bnb-4bit\"\n",
    "#model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.attn_implementation = \"eager\"\n",
    "config.output_attentions = True\n",
    "config.output_hidden_states = False \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "model.to(\"cuda:0\")\n",
    "\n",
    "print(model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JmBmko5YDI0g",
   "metadata": {
    "id": "JmBmko5YDI0g"
   },
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "\n",
    "promptSize = 849  # longueur fixe pour découper le résultat\n",
    "max_prompt_tokens = 300  # limiter le nombre de tokens des lyrics pour économiser de la mémoire\n",
    "\n",
    "def prompt_gender(lyrics, tokenizer=None, max_prompt_tokens=None, device=\"cuda:0\"):\n",
    "    # Tronquer uniquement les lyrics si max_prompt_tokens défini\n",
    "    if max_prompt_tokens is not None and tokenizer is not None:\n",
    "        tokenized_lyrics = tokenizer(lyrics, return_tensors=\"pt\").input_ids[0]\n",
    "        tokenized_lyrics = tokenized_lyrics[:max_prompt_tokens].to(device)\n",
    "        lyrics = tokenizer.decode(tokenized_lyrics, skip_special_tokens=True)\n",
    "\n",
    "    return f\"\"\"You are a gender classifier that labels song lyrics based on whether the narrator appears to be male, female, or neutral. Use lyrical content, tone, and perspective to decide. Your answer must include specific words or phrases from the lyrics that influenced your decision. Return the result using this format:\n",
    "\n",
    "LYRICS: <lyrics>  \n",
    "GENDER: <male|female|neutral>  \n",
    "KEYWORDS: <list of specific words or expressions from the lyrics>\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "LYRICS: I wear my heart upon my sleeve, like a girl who's never been hurt before  \n",
    "GENDER: female  \n",
    "KEYWORDS: \"girl\", \"wear my heart upon my sleeve\"\n",
    "\n",
    "LYRICS: Got my truck and my beer, ain't got no time for games  \n",
    "GENDER: male  \n",
    "KEYWORDS: \"truck\", \"beer\", \"ain't got no time\"\n",
    "\n",
    "LYRICS: The sky is open, my soul is light, I drift where the wind tells me to  \n",
    "GENDER: neutral  \n",
    "KEYWORDS: \"sky\", \"soul\", \"wind\"\n",
    "\n",
    "LYRICS: {lyrics}  \n",
    "GENDER:\"\"\"\n",
    "\n",
    "def getGenre(result):\n",
    "    result = result[promptSize:]\n",
    "    match = re.search(r\"GENDER:\\s*(male|female|neutral)\", result, re.IGNORECASE)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def getGenreLLM_with_attention_and_hidden(lyrics, model, tokenizer, device=\"cuda:0\"):\n",
    "    prompt = prompt_gender(lyrics, tokenizer=tokenizer, max_prompt_tokens=max_prompt_tokens, device=device)\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    model.config.attn_implementation = \"eager\"\n",
    "    model.config.output_attentions = True\n",
    "    model.config.output_hidden_states = True\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward sur le prompt initial\n",
    "        outputs = model(**inputs, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "        attentions_prompt = [att.clone().detach().cpu() for att in outputs.attentions]\n",
    "        hidden_states_prompt_full = outputs.hidden_states[-1].clone().detach().cpu()\n",
    "\n",
    "        # Générer un seul token supplémentaire (greedy top-1)\n",
    "        last_token_logits = outputs.logits[:, -1, :]\n",
    "        next_token_id = torch.argmax(last_token_logits, dim=-1).unsqueeze(-1)\n",
    "        input_with_next = torch.cat([inputs[\"input_ids\"], next_token_id], dim=-1)\n",
    "\n",
    "        # Forward pour le prompt + token généré\n",
    "        outputs_next = model(input_ids=input_with_next, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "        attentions_next = [att.clone().detach().cpu() for att in outputs_next.attentions]\n",
    "        hidden_states_next_full = outputs_next.hidden_states[-1].clone().detach().cpu()\n",
    "\n",
    "        # Extraire uniquement la partie correspondant aux derniers lyrics et au token généré\n",
    "        #prompt_without_lyrics = tokenizer(prompt[0:promptSize], return_tensors=\"pt\").input_ids.to(device)\n",
    "        #len_prompt = prompt_without_lyrics.shape[1]+ 1\n",
    "        \n",
    "        len_prompt = 260\n",
    "        hidden_states_prompt = hidden_states_prompt_full[:, len_prompt:, :]\n",
    "        hidden_states_next = hidden_states_next_full[:, len_prompt:, :]\n",
    "\n",
    "        # Décodage pour récupérer genre\n",
    "        generated_text = tokenizer.decode(input_with_next[0], skip_special_tokens=True)\n",
    "        gender = getGenre(generated_text)\n",
    "\n",
    "        #del prompt_without_lyrics\n",
    "        del outputs, outputs_next, inputs, input_with_next, next_token_id, hidden_states_prompt_full, hidden_states_next_full\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return gender, attentions_prompt, attentions_next, hidden_states_prompt, hidden_states_next, generated_text\n",
    "\n",
    "\n",
    "\n",
    "# --- Exemple d'utilisation ---\n",
    "torch.cuda.empty_cache()\n",
    "lyrics = \"\"\"NA Yeah, Spyderman and Freeze in full effect Uh-huh You ready, Ron? I'm ready You ready, Biv? I'm ready, Slick, are you? Oh, yeah, break it down NA Girl, I, must (warn you) I sense something strange in my mind Situation is (serious) Let's cure it cause we're running out of time It's oh, so (beautiful) Relationships they seem from the start It's all so (deadly) When love is not together from the heart It's drivin' me out of my mind! That's why it's HARD for me to find Can't get it out of my head! Miss her, kiss her, love her(Wrong move you're dead!) That girl is (poison)...Never trust a big butt and smile That girl is (poison)..(\"POISON!!\") NA (-caution) Before I start to meet a fly girl, you know? Cause in some (portions) You'll think she's the best thing in the world She's so - (fly) She'll drive you right out of your mind And steal your heart when you're blind Beware she's schemin', she'll make you think you're dreamin' YOU'LL fall in love and you'll be screamin', demon, HOO.. Poison, deadly, movin' in slow Lookin for a mellow fellow like DeVoe Gettin paid, laid, so better lay low Schemin on house, money, and the whole show The low pro ho she'll be cut like an aaa-FRO See what you're sayin', huh, she's a winner to you But I know she's a loser (How do you know?) Me and the crew used to do her! \"POISON!\" \"POISON!\" \"POISON!\" \"POISON!\" \"POISON!\" \"POISON!\" \"POISON!\" \"POISON! \"POISON!\" \"POISON!\" \"POISON!\" \"POISON! \"POISON!\" \"POISON!\" \"POISON!\" \"POISON! I was at the park, shake, breakin and takin 'em all And that night, I played the wall Checkin' out the fellas, the highs and lows Keepin' one eye open, still clockin' the hoes There was one particular girl that stood out from the rest Poison as can be, the high power chest Michael Biv here and I'm runnin' the show Bell, Biv DeVoe ..now you know! Yo, Slick, blow.. It's drivin' me out of my mind! That's why it's HARD for me to find Can't get it out of my head! Miss her, kiss her, love her(Wrong move you're dead!) That girl is (poison)...Never trust a big butt and smile That girl is (poison)..(\"POISON!!\") Yo' fellas, that was my end of.. You know what I'm sayin', Mike? Yeah, B.B.D. in full effect Yo', wassup to Ralph T and Johnny G And I can't forget about my boy, B. Brown And the whole NE crew Poison.. NA\"\"\"\n",
    "gender, attentions_prompt, attentions_next, hidden_states_prompt, hidden_states_next, generated_text = getGenreLLM_with_attention_and_hidden(lyrics, model, tokenizer)\n",
    "\n",
    "print(f\"Genre : {gender}\")\n",
    "print(f\"Generated text: {generated_text}\")\n",
    "print(\"Shape attentions couche dernière (prompt) :\", attentions_prompt)\n",
    "print(\"Shape attentions couche dernière (prompt + token) :\", attentions_next)\n",
    "print(\"Shape hidden_states dernière couche (lyrics) :\", hidden_states_prompt.shape)\n",
    "print(\"Shape hidden_states dernière couche (lyrics + token) :\", hidden_states_next.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383af90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le nom du modèle et le chemin de sortie\n",
    "\n",
    "modele_str = model_name.split('/')[-1]\n",
    "PATH_output_gender = f'/home/evuichard/Projet DEBIAR/labeled_lyrics_{modele_str}_attention&hidden_states.xlsx'\n",
    "\n",
    "# Vérifier si le fichier de sortie existe et s'il est correctement formaté\n",
    "def need_init(path):\n",
    "  if not os.path.isfile(path):\n",
    "    return True\n",
    "  df_check = pd.read_excel(path, sheet_name=\"Sheet1\")\n",
    "  required_cols = [\n",
    "    'genre_LLM',\n",
    "    'attentions_prompt',\n",
    "    'attentions_next',\n",
    "    'hidden_states_prompt',\n",
    "    'hidden_states_next'\n",
    "  ]\n",
    "  for col in required_cols:\n",
    "    if col not in df_check.columns:\n",
    "      return True\n",
    "  if df_check['genre_LLM'].notna().sum() <= 200:\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "if False and need_init(PATH_output_gender):\n",
    "  df = pd.read_excel('/home/evuichard/Projet DEBIAR/translated_lyrics.xlsx', sheet_name=\"Sheet1\")\n",
    "  df['genre_LLM'] = None\n",
    "  df['attentions_prompt'] = None\n",
    "  df['attentions_next'] = None\n",
    "  df['hidden_states_prompt'] = None\n",
    "  df['hidden_states_next'] = None\n",
    "  df.to_excel(PATH_output_gender, index=False)\n",
    "\n",
    "df = pd.ExcelFile(PATH_output_gender)\n",
    "df = df.parse(\"Sheet1\")\n",
    "df['genre_LLM'] = df['genre_LLM'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AN1hGbroqZv0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 950806,
     "status": "ok",
     "timestamp": 1751916497813,
     "user": {
      "displayName": "Elouan",
      "userId": "04663354146870278787"
     },
     "user_tz": -120
    },
    "id": "AN1hGbroqZv0",
    "outputId": "55672fbd-f177-4a36-d59c-17555f6bfd04"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Créer le dossier de sortie s'il n'existe pas\n",
    "tensor_output_dir = f\"/home/evuichard/Projet DEBIAR/labeled_lyrics_tensors_{modele_str}/gender/\"\n",
    "os.makedirs(tensor_output_dir, exist_ok=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Processing index: {index} / {len(df)}\")\n",
    "\n",
    "    # On skip si genre déjà calculé\n",
    "    if len(str(df['genre_LLM'][index])) > 3:\n",
    "        print(index, end=' ')\n",
    "        continue\n",
    "\n",
    "    lyrics = df['english_lyrics'][index]\n",
    "\n",
    "    # Calculer genre + attentions + hidden states\n",
    "    gender, attentions_prompt, attentions_next, hidden_states_prompt, hidden_states_next, generated_text = getGenreLLM_with_attention_and_hidden(\n",
    "        lyrics, model, tokenizer\n",
    "    )\n",
    "\n",
    "    # Mettre à jour le DataFrame pour le suivi\n",
    "    df.loc[index, 'genre_LLM'] = gender\n",
    "\n",
    "    # Préparer le dict à sauvegarder\n",
    "    data_to_save = {\n",
    "        'genre': gender,\n",
    "        'generated_text': generated_text,\n",
    "        'attentions_prompt': attentions_prompt,\n",
    "        'attentions_next': attentions_next,\n",
    "        'hidden_states_prompt': hidden_states_prompt,\n",
    "        'hidden_states_next': hidden_states_next\n",
    "    }\n",
    "\n",
    "    # Sauvegarder un fichier .pt par ligne\n",
    "    file_path = os.path.join(tensor_output_dir, f\"line_{index}.pt\")\n",
    "    torch.save(data_to_save, file_path)\n",
    "\n",
    "    print(f\"{index} saved, genre: {gender}\")\n",
    "\n",
    "    # Nettoyage mémoire\n",
    "    del attentions_prompt, attentions_next, hidden_states_prompt, hidden_states_next, data_to_save\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fp15QK1wP2v5",
   "metadata": {
    "id": "fp15QK1wP2v5"
   },
   "outputs": [],
   "source": [
    "#mettre en minuscule tous les labels de genre\n",
    "df['genre_LLM'] = df['genre_LLM'].str.lower()\n",
    "df.to_excel(PATH_output_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "def weight_to_ansi(weight):\n",
    "    if weight < 0.5:\n",
    "        ratio = weight / 0.5\n",
    "        r = int(200 * (1 - ratio) + 200 * ratio)\n",
    "        g = int(200 * (1 - ratio) + 0 * ratio)\n",
    "        b = int(200 * (1 - ratio) + 200 * ratio)\n",
    "    else:\n",
    "        ratio = (weight - 0.5) / 0.5\n",
    "        r = int(200 * (1 - ratio) + 255 * ratio)\n",
    "        g = 0\n",
    "        b = int(200 * (1 - ratio) + 0 * ratio)\n",
    "        \n",
    "    ansi_code = rgb_to_ansi(r, g, b)\n",
    "    return ansi_code\n",
    "\n",
    "def rgb_to_ansi(r, g, b):\n",
    "    \"\"\"\n",
    "    Convertit une couleur RGB en code ANSI 256.\n",
    "    \"\"\"\n",
    "    # On approxime à 6 niveaux (0-5)\n",
    "    r = int(r / 51)\n",
    "    g = int(g / 51)\n",
    "    b = int(b / 51)\n",
    "    return 16 + 36*r + 6*g + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_token_to_word(index, tokenizer, tokens = [], prompt =\"\"):\n",
    "    if not tokens:\n",
    "        tokens = tokenizer.encode(prompt)\n",
    "    if abs(index) >= len(tokens):\n",
    "        return None\n",
    "    print(tokens)\n",
    "    return tokenizer.decode([tokens[index]])\n",
    "\n",
    "def index_word_to_token(word, tokenizer, tokens = [], prompt =\"\"):\n",
    "    if not tokens:\n",
    "        tokens = tokenizer.encode(prompt)\n",
    "    token = tokenizer.encode(word)\n",
    "    if token not in tokens:\n",
    "        return None\n",
    "    return tokens.index(token)\n",
    "\n",
    "def visualize_token_indices(prompt, tokenizer, line_width=100):\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    words = [tokenizer.decode([t]) for t in tokens]\n",
    "\n",
    "    current_words, current_indices = \"\", \"\"\n",
    "    char_count = 0\n",
    "\n",
    "    for i, w in enumerate(words):\n",
    "        # si le token contient un saut de ligne -> on affiche le bloc avant de repartir\n",
    "        if \"\\n\" in w:\n",
    "            word_display = colored(w.replace(\"\\n\", \"\"), 'green', attrs=['bold'])\n",
    "            current_words += word_display + \" \"\n",
    "            \n",
    "            idx_str = str(i)\n",
    "            padding = max(len(w.replace(\"\\n\", \"\")) - len(idx_str), 0)\n",
    "            current_indices += \" \" * padding + colored(idx_str, 'cyan', attrs=['bold']) + \" \"\n",
    "            \n",
    "            # impression du bloc courant\n",
    "            print(current_words.rstrip())\n",
    "            print(current_indices.rstrip())\n",
    "            print()  # ligne vide pour séparer\n",
    "\n",
    "            # réinitialiser\n",
    "            current_words, current_indices = \"\", \"\"\n",
    "            char_count = 0\n",
    "            continue\n",
    "\n",
    "        # ajout normal\n",
    "        word_display = colored(w, 'green', attrs=['bold'])\n",
    "        current_words += word_display + \" \"\n",
    "        idx_str = str(i)\n",
    "        padding = max(len(w) - len(idx_str), 0)\n",
    "        current_indices += \" \" * padding + colored(idx_str, 'cyan', attrs=['bold']) + \" \"\n",
    "\n",
    "        char_count += len(w) + 1\n",
    "        if char_count > line_width:\n",
    "            print(current_words.rstrip())\n",
    "            print(current_indices.rstrip())\n",
    "            print()\n",
    "            current_words, current_indices = \"\", \"\"\n",
    "            char_count = 0\n",
    "\n",
    "    # afficher le dernier bloc si non vide\n",
    "    if current_words.strip():\n",
    "        print(current_words.rstrip())\n",
    "        print(current_indices.rstrip())\n",
    "\n",
    "\n",
    "\n",
    "visualize_token_indices(prompt_gender(\"\"), tokenizer)\n",
    "\n",
    "def visualize_weight_sentence(tokenizer, tokens, weights):\n",
    "    \"\"\"\n",
    "    Affiche une phrase avec les tokens colorés suivant leur poids d'importance.\n",
    "    Dégradé continu du gris clair au rouge vif.\n",
    "    \"\"\"\n",
    "    print(len(tokens), len(weights))\n",
    "    if not isinstance(weights, torch.Tensor):\n",
    "        weights = torch.tensor(weights)\n",
    "\n",
    "    # Normalisation des poids\n",
    "    weights = (weights - weights.mean()) / (weights.std() + 1e-5)  # z-score\n",
    "    weights = (weights - weights.min()) / (weights.max() - weights.min() + 1e-5)\n",
    "\n",
    "    spectrum_steps = 10\n",
    "    print(\"Spectre d'importance :\")\n",
    "    for i in range(spectrum_steps):\n",
    "        weight = i / (spectrum_steps - 1)\n",
    "        ansi_code = weight_to_ansi(weight)\n",
    "        print(f\"\\033[48;5;{ansi_code}m \\033[0m\", end='')\n",
    "    print(\"\\n\") \n",
    "    \n",
    "    # Décoder les tokens\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(tokens)\n",
    "    \n",
    "    for token, weight in zip(decoded_tokens, weights):\n",
    "        # Couleur : du gris clair (200,200,200) au rouge vif (255,0,0)\n",
    "        ansi_code = weight_to_ansi(weight)\n",
    "        print(f\"\\033[38;5;{ansi_code}m{token}\\033[0m\", end='')\n",
    "    print()\n",
    "\n",
    "tokens = tokenizer.encode(prompt_gender(\"\")[:50])\n",
    "visualize_weight_sentence(tokenizer, tokens, np.random.rand(len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def call_html():\n",
    "    import IPython\n",
    "    display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))\n",
    "\n",
    "def show_attention_html(tokenizer, attention, tokens, max_tokens_display=300):\n",
    "    \"\"\"\n",
    "    Affiche une view HTML interactive de la matrice d'attention.\n",
    "    Params:\n",
    "      tokenizer: tokenizer avec méthode convert_ids_to_tokens(list_of_ids)\n",
    "      attention: np.array or torch tensor shape (L, H, qlen, klen)\n",
    "      tokens: list/array of token ids (length should match qlen and klen if self-attention)\n",
    "      max_tokens_display: safety cap to avoid insanely long exports\n",
    "    \"\"\"\n",
    "    # Convert to numpy\n",
    "    if hasattr(attention, 'detach'):  # torch tensor\n",
    "        attention = attention.detach().cpu().numpy()\n",
    "    else:\n",
    "        attention = np.array(attention)\n",
    "\n",
    "    if attention.ndim != 4:\n",
    "        raise ValueError(\"attention must be shape (layers, heads, qlen, klen)\")\n",
    "\n",
    "    layers, heads, qlen, klen = attention.shape\n",
    "\n",
    "    # optionally truncate tokens for display if too long\n",
    "    if len(tokens) > max_tokens_display:\n",
    "        raise ValueError(f\"tokens length {len(tokens)} > max_tokens_display {max_tokens_display}. Truncate before calling.\")\n",
    "\n",
    "    # decode tokens to readable strings (subword tokens OK)\n",
    "    try:\n",
    "        decoded = tokenizer.convert_ids_to_tokens(list(tokens))\n",
    "    except Exception:\n",
    "        # fallback: try tokenizer.decode on each id\n",
    "        decoded = []\n",
    "        for t in tokens:\n",
    "            try:\n",
    "                decoded.append(tokenizer.decode([int(t)]))\n",
    "            except Exception:\n",
    "                decoded.append(str(t))\n",
    "\n",
    "    # normalize attention per-layer/head for nicer visualization (we keep raw values but normalize to 0..1)\n",
    "    # We'll produce a nested python list: att_list[layer][head] = 2D list qlen x klen\n",
    "    att_list = []\n",
    "    for l in range(layers):\n",
    "        layer_list = []\n",
    "        for h in range(heads):\n",
    "            mat = attention[l, h]\n",
    "            # clip NaN/inf\n",
    "            mat = np.nan_to_num(mat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            # normalize per-matrix to 0..1 for coloring/stroke width (keeps relative shape)\n",
    "            mmin, mmax = mat.min(), mat.max()\n",
    "            if mmax - mmin < 1e-8:\n",
    "                norm = np.zeros_like(mat).tolist()\n",
    "            else:\n",
    "                norm = ((mat - mmin) / (mmax - mmin)).tolist()\n",
    "            layer_list.append(norm)\n",
    "        att_list.append(layer_list)\n",
    "\n",
    "    data = {\n",
    "        \"tokens\": decoded,\n",
    "        \"layers\": att_list  # shape L x H x q x k\n",
    "    }\n",
    "\n",
    "    # create HTML + JS (D3 v3) viewer\n",
    "    # color mapping function in JS will map weight [0..1] -> rgb (grey->violet->red)\n",
    "    html = f\"\"\"\n",
    "    <div id=\"att_viewer_{id(attention)}\" style=\"font-family: Arial, Helvetica, sans-serif;\"></div>\n",
    "    <script>\n",
    "    (function() {{\n",
    "      require(['d3','jquery'], function(d3, $) {{\n",
    "        var data = {json.dumps(data)};\n",
    "        var tokens = data.tokens;\n",
    "        var layers = data.layers;\n",
    "        var L = layers.length;\n",
    "        var H = layers[0].length;\n",
    "        var container = d3.select(\"#att_viewer_{id(attention)}\");\n",
    "        container.html(''); // reset\n",
    "\n",
    "        // Controls\n",
    "        var controlDiv = container.append('div').style('margin-bottom','6px');\n",
    "        controlDiv.append('label').text('Layer: ');\n",
    "        var layerSel = controlDiv.append('select').attr('id','layer_select');\n",
    "        for (var i=0;i<L;i++) {{\n",
    "          layerSel.append('option').attr('value',i).text(i);\n",
    "        }}\n",
    "        controlDiv.append('span').style('margin','0 10px');\n",
    "        controlDiv.append('label').text('Head: ');\n",
    "        var headSel = controlDiv.append('select').attr('id','head_select');\n",
    "        headSel.append('option').attr('value','all').text('All');\n",
    "        for (var h=0; h<H; h++) {{\n",
    "          headSel.append('option').attr('value',h).text(h);\n",
    "        }}\n",
    "\n",
    "        // Spectrum legend (grey -> violet -> red)\n",
    "        var legend = container.append('div').style('margin','6px 0');\n",
    "        legend.append('span').text('Spectrum: ');\n",
    "        var spec = legend.append('span').style('display','inline-block').style('vertical-align','middle');\n",
    "        var steps = 40;\n",
    "        for (var s=0;s<steps;s++){{\n",
    "          var w = s/(steps-1);\n",
    "          // color computed same as viewer mapping\n",
    "          var col = weightToRgbCss(w);\n",
    "          spec.append('span').style('display','inline-block')\n",
    "                        .style('width','10px').style('height','10px').style('background',col);\n",
    "        }}\n",
    "\n",
    "        // SVG area\n",
    "        var width = Math.min(1000, Math.max(600, tokens.length*18));\n",
    "        var height = Math.min(900, Math.max(300, tokens.length*12));\n",
    "        var svg = container.append('svg').attr('width', width).attr('height', height);\n",
    "        svg.style('background', '#1f1f1f');\n",
    "\n",
    "        // layout constants\n",
    "        var leftX = 120, rightX = width - 120;\n",
    "        var marginTop = 20;\n",
    "        var spacing = (height - 2*marginTop) / Math.max(tokens.length,1);\n",
    "        var tokenY = function(i) {{ return marginTop + i*spacing + spacing/2; }};\n",
    "\n",
    "        // draw token labels\n",
    "        var leftGroup = svg.append('g').attr('class','left');\n",
    "        var rightGroup = svg.append('g').attr('class','right');\n",
    "\n",
    "        leftGroup.selectAll('text')\n",
    "          .data(tokens)\n",
    "          .enter()\n",
    "          .append('text')\n",
    "          .attr('x', leftX - 10)\n",
    "          .attr('y', function(d,i) {{ return tokenY(i); }})\n",
    "          .attr('text-anchor','end')\n",
    "          .style('fill','#dcdcdc')\n",
    "          .style('font-family','monospace')\n",
    "          .style('font-size','11px')\n",
    "          .text(function(d){{\n",
    "            // short token display\n",
    "            return d.length>20 ? d.slice(0,18)+'..' : d;\n",
    "          }});\n",
    "\n",
    "        rightGroup.selectAll('text')\n",
    "          .data(tokens)\n",
    "          .enter()\n",
    "          .append('text')\n",
    "          .attr('x', rightX + 10)\n",
    "          .attr('y', function(d,i) {{ return tokenY(i); }})\n",
    "          .attr('text-anchor','start')\n",
    "          .style('fill','#dcdcdc')\n",
    "          .style('font-family','monospace')\n",
    "          .style('font-size','11px')\n",
    "          .text(function(d){{\n",
    "            return d.length>20 ? d.slice(0,18)+'..' : d;\n",
    "          }});\n",
    "\n",
    "        // container for links\n",
    "        var linkGroup = svg.append('g').attr('class','links');\n",
    "\n",
    "        // helper: color mapping grey->violet->red for weight in [0,1]\n",
    "        function weightToRgbCss(w) {{\n",
    "          // w in [0,1]\n",
    "          var r,g,b;\n",
    "          if (w < 0.5) {{\n",
    "            var ratio = w / 0.5;\n",
    "            r = Math.round(200*(1-ratio) + 200*ratio);\n",
    "            g = Math.round(200*(1-ratio) + 0*ratio);\n",
    "            b = Math.round(200*(1-ratio) + 200*ratio);\n",
    "          }} else {{\n",
    "            var ratio = (w-0.5)/0.5;\n",
    "            r = Math.round(200*(1-ratio) + 255*ratio);\n",
    "            g = 0;\n",
    "            b = Math.round(200*(1-ratio) + 0*ratio);\n",
    "          }}\n",
    "          return 'rgb('+r+','+g+','+b+')';\n",
    "        }}\n",
    "\n",
    "        // draw/update function\n",
    "        function update() {{\n",
    "          var layer = +d3.select('#layer_select').node().value;\n",
    "          var headVal = d3.select('#head_select').node().value;\n",
    "          var mat; // q x k\n",
    "          if (headVal === 'all') {{\n",
    "            // average across heads\n",
    "            var sum = [];\n",
    "            var first = layers[layer][0];\n",
    "            var q = first.length, k = first[0].length;\n",
    "            for (var i=0;i<q;i++) {{\n",
    "              sum.push(new Array(k).fill(0.0));\n",
    "            }}\n",
    "            for (var h=0; h<layers[layer].length; h++) {{\n",
    "              var m = layers[layer][h];\n",
    "              for (var i=0;i<q;i++) for (var j=0;j<k;j++) sum[i][j] += m[i][j];\n",
    "            }}\n",
    "            for (var i=0;i<q;i++) for (var j=0;j<k;j++) sum[i][j] /= layers[layer].length;\n",
    "            mat = sum;\n",
    "          }} else {{\n",
    "            mat = layers[layer][+headVal];\n",
    "          }}\n",
    "\n",
    "          // flatten matrix entries into list of links with positions and weight\n",
    "          var links = [];\n",
    "          var q = mat.length, k = mat[0].length;\n",
    "          for (var i=0;i<q;i++) {{\n",
    "            for (var j=0;j<k;j++) {{\n",
    "              var w = mat[i][j];\n",
    "              // optional threshold: don't show very tiny links to reduce clutter\n",
    "              if (w <= 0.01) continue;\n",
    "              links.push({{source:i, target:j, weight:w}});\n",
    "            }}\n",
    "          }}\n",
    "\n",
    "          // bind data\n",
    "          var selection = linkGroup.selectAll('path.link').data(links, function(d) {{ return d.source+','+d.target; }});\n",
    "\n",
    "          // exit\n",
    "          selection.exit().transition().duration(200).style('opacity',0).remove();\n",
    "\n",
    "          // enter\n",
    "          var enter = selection.enter().append('path').attr('class','link')\n",
    "            .attr('fill','none')\n",
    "            .attr('stroke-linecap','round')\n",
    "            .attr('stroke-opacity',0.9)\n",
    "            .attr('stroke-width',1)\n",
    "            .style('mix-blend-mode','screen');\n",
    "\n",
    "          // update + enter merged\n",
    "          selection = enter.merge(selection);\n",
    "          selection.each(function(d) {{\n",
    "            var sy = tokenY(d.source);\n",
    "            var ty = tokenY(d.target);\n",
    "            // nice curved path between leftX and rightX\n",
    "            var mx = (leftX + rightX)/2;\n",
    "            var path = 'M'+leftX+','+sy+' C'+mx+','+sy+' '+mx+','+ty+' '+rightX+','+ty;\n",
    "            d3.select(this).attr('d', path)\n",
    "              .attr('stroke', weightToRgbCss(d.weight))\n",
    "              .attr('stroke-width', Math.max(0.4, 6 * d.weight))  // stroke width scaling (tweakable)\n",
    "              .attr('opacity', Math.min(1.0, 0.3 + 0.7*d.weight));\n",
    "          }});\n",
    "        }}\n",
    "\n",
    "        // first draw\n",
    "        update();\n",
    "\n",
    "        // events\n",
    "        d3.select('#layer_select').on('change', update);\n",
    "        d3.select('#head_select').on('change', update);\n",
    "\n",
    "      }}); // require\n",
    "    }})(); \n",
    "    </script>\n",
    "    \"\"\"\n",
    "\n",
    "    # display loader + viewer\n",
    "    call_html()\n",
    "    display(HTML(html))\n",
    "\n",
    "# Example usage:\n",
    "# show_attention_html(tokenizer, attention_np_array, tokens_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba984acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "def visualize_attention_html(tokenizer, attention, tokens):\n",
    "    \"\"\"\n",
    "    Affiche une matrice d'attention en HTML.\n",
    "    \n",
    "    tokenizer : tokenizer pour décoder les tokens\n",
    "    attention : np.array ou torch.Tensor de shape (num_layers, num_heads, seq_len, seq_len)\n",
    "    tokens : tensor ou liste des tokens d'entrée\n",
    "    \n",
    "    layer : couche de la matrice à visualiser\n",
    "    head : tête à visualiser\n",
    "    \"\"\"\n",
    "    # Si torch tensor, convertir en numpy\n",
    "    if 'torch' in str(type(attention)):\n",
    "        attention = attention.detach().cpu().numpy()\n",
    "    \n",
    "    # Sélection de la couche et tête\n",
    "    att_matrix = attention\n",
    "    \n",
    "    # Décoder les tokens\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(tokens)\n",
    "    \n",
    "    # Normalisation pour couleur\n",
    "    att_norm = (att_matrix - att_matrix.min()) / (att_matrix.max() - att_matrix.min() + 1e-8)\n",
    "    \n",
    "    # Générer tableau HTML\n",
    "    html = \"<table style='border-collapse: collapse;'>\"\n",
    "    \n",
    "    # Première ligne : tokens en colonnes\n",
    "    html += \"<tr><th></th>\"\n",
    "    for tok in decoded_tokens:\n",
    "        html += f\"<th style='padding:2px; font-family:monospace;'>{tok}</th>\"\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "    # Lignes de la matrice\n",
    "    for i, tok_row in enumerate(decoded_tokens):\n",
    "        html += f\"<tr><th style='padding:2px; font-family:monospace;'>{tok_row}</th>\"\n",
    "        for j in range(len(decoded_tokens)):\n",
    "            val = att_norm[i, j]\n",
    "            # Dégradé bleu clair → bleu foncé\n",
    "            r = int(255*(1-val))\n",
    "            g = int(255*(1-val))\n",
    "            b = int(255*val)\n",
    "            color = f'rgb({r},{g},{b})'\n",
    "            html += f\"<td style='background-color:{color}; width:20px; height:20px; text-align:center;'>{val:.2f}</td>\"\n",
    "        html += \"</tr>\"\n",
    "    \n",
    "    html += \"</table>\"\n",
    "    \n",
    "    display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa03f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def PCA_on_dim_n(tensor, dim=0, n_espace_propre=0):\n",
    "    if tensor.dim() <= dim:\n",
    "        raise ValueError(\"La dimension spécifiée est supérieure à la dimension du tenseur.\")\n",
    "    permute_order = list(range(tensor.dim()))\n",
    "    permute_order.append(permute_order.pop(dim))  \n",
    "    tensor_perm = tensor.permute(*permute_order)  # shape: (..., target_dim)\n",
    "    shape_perm = tensor_perm.shape\n",
    "    tensor_reshaped = tensor_perm.reshape(-1, shape_perm[-1]).detach().cpu().numpy()\n",
    "    \n",
    "    pca = PCA()\n",
    "    pca.fit(tensor_reshaped)\n",
    "    \n",
    "    if n_espace_propre >= pca.components_.shape[0]:\n",
    "        raise ValueError(f\"n_espace_propre={n_espace_propre} dépasse le nombre de composantes ({pca.components_.shape[0]})\")\n",
    "\n",
    "    reduced = np.dot(tensor_reshaped, pca.components_[n_espace_propre].T).reshape(*shape_perm[:-1], 1)\n",
    "    reduced_torch = torch.from_numpy(reduced).to(tensor.device)\n",
    "    \n",
    "    inv_permute = [0] * len(permute_order)\n",
    "    for i, j in enumerate(permute_order):\n",
    "        inv_permute[j] = i\n",
    "    reduced_torch = reduced_torch.permute(*inv_permute)\n",
    "\n",
    "    return reduced_torch.squeeze(dim)\n",
    "\n",
    "\n",
    "\n",
    "#### Weight - methods ####\n",
    "## vertical\n",
    "def weight_vertical_idToken(attention, idToken):\n",
    "    # attention : (seq_len, seq_len)\n",
    "    # output : tenseur de dimension (seq_len)\n",
    "    return attention[:, idToken]\n",
    "\n",
    "def weight_vertical_token(attention, idToken, tokens):\n",
    "    indices = [i for i, token in enumerate(tokens) if token == tokens[idToken]]\n",
    "    return attention[:, indices].mean(dim=1)\n",
    "\n",
    "def weight_vertical_mean(attention):\n",
    "    # attention : (seq_len, seq_len)\n",
    "    # output : tenseur de dimension (seq_len)\n",
    "    return attention.mean(dim=1)\n",
    "\n",
    "def weight_vertical_PCA(attention):\n",
    "    # attention : (seq_len,seq_len)\n",
    "    # Utilisation de sklearn pour faire une ACP sur l'axe 1 du tenseur\n",
    "    return PCA_on_dim_n(attention, dim=1)\n",
    "\n",
    "## horizontal\n",
    "def weight_horizontal_idToken(attention, idToken):\n",
    "    # attention : (seq_len, seq_len)\n",
    "    # output : tenseur de dimension (seq_len)\n",
    "    return attention[idToken, :]\n",
    "\n",
    "def weight_horizontal_token(attention, idToken, tokens):\n",
    "    indices = [i for i, token in enumerate(tokens) if token == tokens[idToken]]\n",
    "    return attention[indices, :].mean(dim=0)\n",
    "\n",
    "def weight_horizontal_mean(attention):\n",
    "    # attention : (seq_len, seq_len)\n",
    "    # output : tenseur de dimension (seq_len)\n",
    "    return attention.mean(dim=0)\n",
    "\n",
    "def weight_horizontal_PCA(attention):\n",
    "    # attention : (seq_len, seq_len)\n",
    "    # Chaque colonne est un échantillon, chaque ligne une feature\n",
    "    return PCA_on_dim_n(attention, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ceae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tensor(tensor):\n",
    "    norm = torch.linalg.norm(tensor)\n",
    "    return tensor / norm\n",
    "\n",
    "def normalize_tensor_col(tensor):\n",
    "    # tensor contenant les normes de chaque colonne de la matrice tensor\n",
    "    norm = torch.linalg.norm(tensor, dim=0, keepdim=True)\n",
    "    # on divise chaque colonne par sa norme\n",
    "    return tensor / norm\n",
    "\n",
    "def normalize_tensor_row(tensor):\n",
    "    norm = torch.linalg.norm(tensor, dim=1, keepdim=True)\n",
    "    # on divise chaque ligne par sa norme\n",
    "    return tensor / norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtre_id_tensor(tensor,dim,id_start,id_end=0):\n",
    "    #sur la dimension spécifiée, ne garde que les indices entre id_start et id_end et met le reste à 0 (donc sans réduction de dimension)\n",
    "    if id_end == 0:\n",
    "        id_end = tensor.size(dim)\n",
    "    indices = torch.arange(tensor.size(dim), device=tensor.device)\n",
    "    mask_dim = (indices >= id_start) & (indices <= id_end)\n",
    "    shape = [1] * tensor.dim()\n",
    "    shape[dim] = -1\n",
    "    mask = mask_dim.view(shape)\n",
    "    return tensor * mask\n",
    "\n",
    "def reduce_id_tensor(tensor,dim,id_start,id_end=0):\n",
    "    # sur la dimension spécifiée, ne garde que les indices entre id_start et id_end, et réduit la dimension\n",
    "    if id_end == 0:\n",
    "        id_end = tensor.size(dim)\n",
    "    return tensor.narrow(dim, id_start, id_end - id_start)\n",
    "\n",
    "def idee_verticale(attentions, tokens, id_fin_prompt):\n",
    "    idToken = -1\n",
    "    indices = [i for i, token in enumerate(tokens) if token == tokens[idToken]]\n",
    "    filtre_indices = attentions\n",
    "    print(\"Shape of filtre_indices:\", filtre_indices.shape)\n",
    "    projection1 = reduce_id_tensor(filtre_indices, dim=-2, id_start=id_fin_prompt)\n",
    "    projection1 = PCA_on_dim_n(projection1, dim=-1)\n",
    "    print(\"Shape of projection1:\", projection1.shape)\n",
    "    projection2 = PCA_on_dim_n(projection1, dim=1)\n",
    "    print(\"Shape of projection2:\", projection2.shape)\n",
    "    projection3 = PCA_on_dim_n(projection2, dim=0)\n",
    "    print(\"Shape of projection3:\", projection3.shape)\n",
    "    return projection3\n",
    "\n",
    "def idee_horizontale(attentions, tokens, id_fin_prompt):\n",
    "    idToken = -1\n",
    "    indices = [i for i, token in enumerate(tokens) if token == tokens[idToken]]\n",
    "    filtre_indices = attentions\n",
    "    print(\"Shape of filtre_indices:\", filtre_indices.shape)\n",
    "    projection1 = reduce_id_tensor(filtre_indices, dim=-1, id_start=id_fin_prompt)\n",
    "    projection1 = PCA_on_dim_n(projection1, dim=-2)\n",
    "    print(\"Shape of projection1:\", projection1.shape)\n",
    "    projection2 = PCA_on_dim_n(projection1, dim=1)\n",
    "    print(\"Shape of projection2:\", projection2.shape)\n",
    "    projection3 = PCA_on_dim_n(projection2, dim=0)\n",
    "    print(\"Shape of projection3:\", projection3.shape)\n",
    "    return projection3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24967e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(df,index):\n",
    "    return df.loc[index, 'english_lyrics']\n",
    "\n",
    "def get_prompt_for_line(df,index, troncage = -1, tokenizer = None):\n",
    "    if troncage > 0:\n",
    "        lyrics = get_lyrics(df,index)\n",
    "        tokens = tokenizer.encode(lyrics)\n",
    "        tokens = tokens[:troncage]\n",
    "        lyrics = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "        return prompt_gender(lyrics)\n",
    "    return prompt_gender(get_lyrics(df,index))\n",
    "\n",
    "def load_attention_and_prompt_from_index(index, next = False):\n",
    "    Path_tensor_gender = f\"/home/evuichard/Projet DEBIAR/labeled_lyrics_tensors_{modele_str}/gender/\" + f\"/line_{index}.pt\"\n",
    "    data_tensor = torch.load(Path_tensor_gender)\n",
    "    if next:\n",
    "        attention = torch.stack(data_tensor['attentions_next'])[:,0,:,:,:]\n",
    "        print(\"Shape of attention (next):\", attention.shape)\n",
    "        return attention, data_tensor['generated_text']\n",
    "    attention = torch.stack(data_tensor['attentions_prompt'])[:,0,:,:,:]\n",
    "    prompt = data_tensor['generated_text']\n",
    "    c = prompt[-1]\n",
    "    prompt = prompt[:-1]\n",
    "    while prompt and c != ' ' and c != ':':\n",
    "        c = prompt[-1]\n",
    "        prompt = prompt[:-1]\n",
    "    return attention, prompt\n",
    "\n",
    "def attentionsToAttention(attentions):\n",
    "    #reduction layer\n",
    "    #attention = attentions.mean(dim=0)\n",
    "    #attention = attentions[-1]\n",
    "    attention = PCA_on_dim_n(attentions)\n",
    "    print(\"Shape of attention (layer):\", attention.shape)\n",
    "    #reduction head\n",
    "    #attention = attention.mean(dim=0)\n",
    "    #attention = attention[-1]\n",
    "    attention = PCA_on_dim_n(attention)\n",
    "    print(\"Shape of attention (head):\", attention.shape)\n",
    "    return attention\n",
    "\n",
    "def visualize_attention_from_index_and_idToken(index, tokenizer):\n",
    "    attentions, prompt = load_attention_and_prompt_from_index(index, next=True)\n",
    "    attention = attentionsToAttention(attentions)\n",
    "    print(\"Shape of attention:\", attention.shape)\n",
    "\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    print(\"Shape of tokens:\", len(tokens))\n",
    "\n",
    "    weights = weight_horizontal_token(attention,-1,tokens)\n",
    "    print(\"Shape of weights (horizontal, idToken):\", weights.shape)\n",
    "    visualize_weight_sentence(tokenizer, tokens, weights)\n",
    "\n",
    "    weights = weight_vertical_token(attention,-1,tokens)\n",
    "    print(\"Shape of weights (vertical, idToken):\", weights.shape)\n",
    "    visualize_weight_sentence(tokenizer, tokens, weights)\n",
    "\n",
    "    call_html()\n",
    "    show_attention_html(tokenizer, attentions[:,:,263:,263:], tokens[263:],306)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_excel('/home/evuichard/Projet DEBIAR/translated_lyrics.xlsx', sheet_name=\"Sheet1\")\n",
    "\n",
    "visualize_attention_from_index_and_idToken(108, tokenizer)\n",
    "\n",
    "def visualize_attention_idee(index,tokenizer):\n",
    "    attentions, prompt = load_attention_and_prompt_from_index(index, next=True)\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    len_prompt = 263 #len(tokenizer.encode(prompt_gender(\"\")))\n",
    "\n",
    "    weight_horizontal = idee_horizontale(attentions, tokens, len_prompt)\n",
    "    visualize_weight_sentence(tokenizer, tokens[len_prompt:], weight_horizontal)\n",
    "\n",
    "    weight_vertical = idee_verticale(attentions, tokens, len_prompt)\n",
    "    visualize_weight_sentence(tokenizer, tokens[len_prompt:], weight_vertical)\n",
    "\n",
    "#visualize_attention_idee(90, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k3GQiEsbDN4a",
   "metadata": {
    "id": "k3GQiEsbDN4a"
   },
   "source": [
    "# Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpX9byBEdces",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1751916499626,
     "user": {
      "displayName": "Elouan",
      "userId": "04663354146870278787"
     },
     "user_tz": -120
    },
    "id": "gpX9byBEdces",
    "outputId": "1a778e4d-5d2f-49e3-abf9-f0ce255a0610"
   },
   "outputs": [],
   "source": [
    "print(len(\"\"\"You are a gender classifier that labels song lyrics based on whether the narrator appears to be male, female, or neutral. Use lyrical content, tone, and perspective to decide. Your answer must include specific words or phrases from the lyrics that influenced your decision. Return the result using this format:\n",
    "\n",
    "LYRICS: <lyrics>  \n",
    "GENDER: <male|female|neutral>  \n",
    "KEYWORDS: <list of specific words or expressions from the lyrics>\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "LYRICS: I wear my heart upon my sleeve, like a girl who's never been hurt before  \n",
    "GENDER: female  \n",
    "KEYWORDS: \"girl\", \"wear my heart upon my sleeve\"\n",
    "\n",
    "LYRICS: Got my truck and my beer, ain't got no time for games  \n",
    "GENDER: male  \n",
    "KEYWORDS: \"truck\", \"beer\", \"ain't got no time\"\n",
    "\n",
    "LYRICS: The sky is open, my soul is light, I drift where the wind tells me to  \n",
    "GENDER: neutral  \n",
    "KEYWORDS: \"sky\", \"soul\", \"wind\"\n",
    "\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ZXtR3C3PyX6",
   "metadata": {
    "id": "3ZXtR3C3PyX6"
   },
   "outputs": [],
   "source": [
    "promptSize = 1042 #502\n",
    "def prompt_ethnicity(lyrics):\n",
    "  return f\"\"\"You are an ethnicity classifier. Based on a block of song lyrics written in English, determine the most likely cultural or ethnic background of the narrator. Use references to places, culture, language style, and musical or thematic elements.\n",
    "\n",
    "Choose only one of the following labels:\n",
    "- European\n",
    "- Asian\n",
    "- African\n",
    "- Arabic\n",
    "- North American\n",
    "- Latino / South American\n",
    "- Oceania\n",
    "\n",
    "Return the result in the following format:\n",
    "LYRICS: <lyrics>  \n",
    "ETHNICITY: <label>  \n",
    "KEYWORDS: <list of specific words or expressions from the lyrics that led to your decision>\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "LYRICS: From Lagos to the stage, I carry my father's name / Afrobeat in my soul, fire in my veins  \n",
    "ETHNICITY: African  \n",
    "KEYWORDS: \"Lagos\", \"Afrobeat\", \"father's name\"\n",
    "\n",
    "LYRICS: I grew up on ramen and neon lights / Tokyo dreams in sleepless nights  \n",
    "ETHNICITY: Asian  \n",
    "KEYWORDS: \"ramen\", \"Tokyo\", \"neon lights\"\n",
    "\n",
    "LYRICS: Raised on southern blues and faded jeans / Mama's voice and Georgia dreams  \n",
    "ETHNICITY: North American  \n",
    "KEYWORDS: \"southern blues\", \"faded jeans\", \"Georgia\"\n",
    "\n",
    "LYRICS: {lyrics}  \n",
    "ETHNICITY:\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def getEthnicityAndKeywords(result):\n",
    "  result = result[promptSize:]\n",
    "  match = re.search(\n",
    "    r\"ETHNICITY:\\s*(European|Asian|African|Arabic|North American|Latino / South American|Oceania)\\s*KEYWORDS:\\s*([^\\n]+)\",\n",
    "    result,\n",
    "    re.IGNORECASE\n",
    "  )\n",
    "  if match:\n",
    "    ethnie = match.group(1)\n",
    "    keywords_str = match.group(2).strip()\n",
    "    # Remove quotes and split by comma\n",
    "    keywords_list = [kw.strip().replace('\"', '').replace('\\'', '') for kw in keywords_str.split(',') if kw.strip().replace('\"', '').replace('\\'', '')]\n",
    "    keywords_list = list(set(keywords_list))  # Remove duplicates\n",
    "    return ethnie, keywords_list\n",
    "  else:\n",
    "    print(\"Impossible d'extraire l'ethnie ou les mots-clés.\")\n",
    "    print(result)\n",
    "    return None, None\n",
    "\n",
    "def getEthnicityAndReasonLLM(lyrics):\n",
    "  prompt = prompt_ethnicity(lyrics)\n",
    "  result = pipe(prompt, max_new_tokens=100, do_sample=False) # Removed temperature=0.7\n",
    "  output_text = result[0][\"generated_text\"]\n",
    "  return getEthnicityAndKeywords(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NmjEDDueSoIq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9297,
     "status": "ok",
     "timestamp": 1751916508934,
     "user": {
      "displayName": "Elouan",
      "userId": "04663354146870278787"
     },
     "user_tz": -120
    },
    "id": "NmjEDDueSoIq",
    "outputId": "6e5061b7-d5df-4ded-a331-3c6bcd7b927b"
   },
   "outputs": [],
   "source": [
    "df = pd.ExcelFile(PATH_output_gender)\n",
    "df = df.parse(\"Sheet1\")\n",
    "print(getEthnicityAndReasonLLM(df['english_lyrics'][0]))\n",
    "#if df don't already have 'ethnicity_LLM' key\n",
    "if 'ethnicity_LLM' not in df.columns or 'keywords_LLM_Ethicity' not in df.columns:\n",
    "  df['ethnicity_LLM'] = None\n",
    "  df['keywords_LLM_Ethicity'] = None\n",
    "  df.to_excel(PATH_output_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6LEEnPg6UGOK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1609300,
     "status": "ok",
     "timestamp": 1751918118261,
     "user": {
      "displayName": "Elouan",
      "userId": "04663354146870278787"
     },
     "user_tz": -120
    },
    "id": "6LEEnPg6UGOK",
    "outputId": "497545f1-56ee-4316-855f-dd1326234a12"
   },
   "outputs": [],
   "source": [
    "df['ethnicity_LLM'] = df['ethnicity_LLM'].astype('object')\n",
    "df['keywords_LLM_Ethicity'] = df['keywords_LLM_Ethicity'].astype('object')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  \"\"\"if index > 200:\n",
    "    print(\"Temps limite atteint.\")\n",
    "    break\"\"\"\n",
    "  if index % 100 == 0:\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Processing index: {index} / {len(df)}\")\n",
    "  if len(str(df['ethnicity_LLM'][index])) > 3:\n",
    "    print(df['ethnicity_LLM'][index])\n",
    "    print(index, end=' ')\n",
    "    continue\n",
    "  genre, keywords = getEthnicityAndReasonLLM(df['english_lyrics'][index])\n",
    "  df.loc[index, 'ethnicity_LLM'] = genre\n",
    "  df.loc[index, 'keywords_LLM_Ethicity'] = \", \".join(keywords) if keywords else None\n",
    "  df.to_excel(PATH_output_gender)\n",
    "  print(index, genre, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uCuiB-ZQylJn",
   "metadata": {
    "id": "uCuiB-ZQylJn"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(PATH_output_gender)\n",
    "#on affiche le nom des artistes qui ont pour genre \"person\"\n",
    "print(df[df['genre'] == 'Person']['track_artist'].unique())\n",
    "#SAYMYNAME => female\n",
    "#Aleman => male\n",
    "#Fili => group\n",
    "#MiMS => male\n",
    "\n",
    "df.loc[df['track_artist'] == 'SAYMYNAME', 'genre'] = 'female'\n",
    "df.loc[df['track_artist'] == 'Aleman', 'genre'] = 'male'\n",
    "df.loc[df['track_artist'] == 'Fili', 'genre'] = 'group'\n",
    "df.loc[df['track_artist'] == 'MiMS', 'genre'] = 'male'\n",
    "df = df.dropna(subset=['genre'])\n",
    "df.to_excel(PATH_output_gender, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "KXQltZsTDd63",
    "JmBmko5YDI0g"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
