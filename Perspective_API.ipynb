{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from googleapiclient import discovery\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"PCA_TOKEN\")\n",
    "\n",
    "output_PATH = \"C:\\\\Users\\\\Elouan\\\\Documents\\\\Projet Biais LLM\\\\Projet-DEBIAR---Labellisation-and-hidden-states\\\\lyrics_toxicities.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du client\n",
    "client = discovery.build(\n",
    "    \"commentanalyzer\",\n",
    "    \"v1alpha1\",\n",
    "    developerKey=API_KEY,\n",
    "    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "    static_discovery=False,\n",
    ")\n",
    "\n",
    "# Exemple : une phrase de test\n",
    "text = \"I hate you, you're the worst.\"\n",
    "\n",
    "analyze_request = {\n",
    "    'comment': {'text': text},\n",
    "    'requestedAttributes': {\n",
    "        'TOXICITY': {},\n",
    "        'INSULT': {},\n",
    "        'PROFANITY': {},\n",
    "        'IDENTITY_ATTACK': {},\n",
    "        'THREAT': {}\n",
    "    }\n",
    "}\n",
    "\n",
    "response = client.comments().analyze(body=analyze_request).execute()\n",
    "print(\"Toxicity : \", response['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "print(\"Insult : \", response['attributeScores']['INSULT']['summaryScore']['value'])\n",
    "print(\"Profanity : \", response['attributeScores']['PROFANITY']['summaryScore']['value'])\n",
    "print(\"Identity Attack : \", response['attributeScores']['IDENTITY_ATTACK']['summaryScore']['value'])\n",
    "print(\"Threat : \", response['attributeScores']['THREAT']['summaryScore']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_lyrics = pd.read_excel(\"C:\\\\Users\\\\Elouan\\\\Documents\\\\Projet Biais LLM\\\\Projet-DEBIAR---Labellisation-and-hidden-states\\\\translated_lyrics.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "df_lyrics_toxicities = pd.DataFrame()\n",
    "df_lyrics_toxicities['track_name'] = df_lyrics['track_name']\n",
    "df_lyrics_toxicities['track_artist'] = df_lyrics['track_artist']\n",
    "df_lyrics_toxicities['english_lyrics'] = df_lyrics['english_lyrics']\n",
    "\n",
    "del df_lyrics\n",
    "print(df_lyrics_toxicities.head())\n",
    "df_lyrics_toxicities['toxicity'] = None\n",
    "df_lyrics_toxicities['insult'] = None\n",
    "df_lyrics_toxicities['profanity'] = None\n",
    "df_lyrics_toxicities['identity_attack'] = None\n",
    "df_lyrics_toxicities['threat'] = None\n",
    "df_lyrics_toxicities['sexually_explicit'] = None\n",
    "df_lyrics_toxicities['flirtation'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4213962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for index, row in df_lyrics_toxicities.iterrows():\n",
    "    text = row['english_lyrics']\n",
    "    analyze_request = {\n",
    "        'comment': {'text': text},\n",
    "        'requestedAttributes': {\n",
    "            'TOXICITY': {},\n",
    "            'INSULT': {},\n",
    "            'PROFANITY': {},\n",
    "            'IDENTITY_ATTACK': {},\n",
    "            'THREAT': {},\n",
    "            'SEXUALLY_EXPLICIT': {},\n",
    "            'FLIRTATION': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    time.sleep(1)   # Pause d'une seconde pour éviter de dépasser les limites de l'API\n",
    "    try:\n",
    "        response = client.comments().analyze(body=analyze_request).execute()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {index+2}, \\\"{row['track_name']}\\\": {e}\")\n",
    "        continue\n",
    "    \n",
    "    df_lyrics_toxicities.at[index, 'toxicity'] = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "    df_lyrics_toxicities.at[index, 'insult'] = response['attributeScores']['INSULT']['summaryScore']['value']\n",
    "    df_lyrics_toxicities.at[index, 'profanity'] = response['attributeScores']['PROFANITY']['summaryScore']['value']\n",
    "    df_lyrics_toxicities.at[index, 'identity_attack'] = response['attributeScores']['IDENTITY_ATTACK']['summaryScore']['value']\n",
    "    df_lyrics_toxicities.at[index, 'threat'] = response['attributeScores']['THREAT']['summaryScore']['value']\n",
    "    df_lyrics_toxicities.at[index, 'sexually_explicit'] = response['attributeScores']['SEXUALLY_EXPLICIT']['summaryScore']['value']\n",
    "    df_lyrics_toxicities.at[index, 'flirtation'] = response['attributeScores']['FLIRTATION']['summaryScore']['value']\n",
    "\n",
    "    if index % 10 == 0:\n",
    "        print(f\"Processing row {index}/{len(df_lyrics_toxicities)}\")\n",
    "        df_lyrics_toxicities.to_excel(output_PATH, index=False)\n",
    "        if index % 50 == 0: #afficher la ligne actuelle\n",
    "            print(df_lyrics_toxicities.iloc[index])\n",
    "\n",
    "df_lyrics_toxicities.to_excel(output_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty lines in\n",
    "df_lyrics_toxicities = df_lyrics_toxicities.dropna(subset=['toxicity'])\n",
    "df_lyrics_toxicities.to_excel(output_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46183088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics_toxicities = pd.read_excel(output_PATH,sheet_name=\"Sheet1\")\n",
    "\n",
    "#on récupère les données labellisées d'un modèle données afin de faire un histogramme des toxicités des paroles de chansons par label\n",
    "model_name = \"unsloth/Mistral-Small-Instruct-2409-bnb-4bit\"\n",
    "#model_name = \"unsloth/Phi-4-mini-instruct-bnb-4bit\"\n",
    "#model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B-bnb-4bit\"\n",
    "#model_name = \"unsloth/Qwen2-7B-Instruct-bnb-4bit\"\n",
    "#model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "\n",
    "modele_str = model_name.split('/')[-1]\n",
    "df_labeled_lyrics = pd.read_excel(f\"C:\\\\Users\\\\Elouan\\\\Documents\\\\Projet Biais LLM\\\\Projet-DEBIAR---Labellisation-and-hidden-states\\\\labeled_lyrics_gender_{modele_str}.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "df_lyrics_toxicities['label'] = None\n",
    "\n",
    "for index, row in df_lyrics_toxicities.iterrows():\n",
    "    matching_rows = df_labeled_lyrics[(df_labeled_lyrics['track_name'] == row['track_name']) & (df_labeled_lyrics['track_artist'] == row['track_artist'])]\n",
    "    if matching_rows.empty:\n",
    "        continue\n",
    "    df_lyrics_toxicities.at[index, 'label'] = matching_rows.iloc[0]['ethnicity_LLM']\n",
    "\n",
    "df_lyrics_toxicities.to_excel(output_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['toxicity', 'insult', 'profanity', 'identity_attack', 'threat', 'sexually_explicit', 'flirtation']\n",
    "\n",
    "df_lyrics_toxicities[cols] = df_lyrics_toxicities[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df_for_group = df_lyrics_toxicities.dropna(subset=['label'])\n",
    "\n",
    "average_toxicity_per_label = df_for_group.groupby('label')[cols].mean()\n",
    "print(average_toxicity_per_label)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "average_toxicity_per_label.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average Toxicity Metrics per Label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Average Score')\n",
    "plt.legend(title='Toxicity Metrics')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"average_toxicity_per_label3_{modele_str}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759255df",
   "metadata": {},
   "outputs": [],
   "source": [
    "del API_KEY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
